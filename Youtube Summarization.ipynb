{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "DVtzS40LC3iw"
      },
      "source": [
        "#Youtube Summarizer (Gen AI Project)\n",
        "\n",
        "YouTube video summarizers are tools that condense long videos into shorter, more manageable summaries. They extract key points and essential information from the video, providing a concise overview without the need to watch the entire content."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "uydmV-8_1Heq",
        "outputId": "7f86ce46-0ddc-4107-cd05-ebcaee63bae8"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Requirement already satisfied: transformers in /usr/local/lib/python3.10/dist-packages (4.40.2)\n",
            "Requirement already satisfied: youtube-transcript-api in /usr/local/lib/python3.10/dist-packages (0.6.2)\n",
            "Requirement already satisfied: sentencepiece in /usr/local/lib/python3.10/dist-packages (0.1.99)\n",
            "Requirement already satisfied: filelock in /usr/local/lib/python3.10/dist-packages (from transformers) (3.14.0)\n",
            "Requirement already satisfied: huggingface-hub<1.0,>=0.19.3 in /usr/local/lib/python3.10/dist-packages (from transformers) (0.20.3)\n",
            "Requirement already satisfied: numpy>=1.17 in /usr/local/lib/python3.10/dist-packages (from transformers) (1.25.2)\n",
            "Requirement already satisfied: packaging>=20.0 in /usr/local/lib/python3.10/dist-packages (from transformers) (24.0)\n",
            "Requirement already satisfied: pyyaml>=5.1 in /usr/local/lib/python3.10/dist-packages (from transformers) (6.0.1)\n",
            "Requirement already satisfied: regex!=2019.12.17 in /usr/local/lib/python3.10/dist-packages (from transformers) (2023.12.25)\n",
            "Requirement already satisfied: requests in /usr/local/lib/python3.10/dist-packages (from transformers) (2.31.0)\n",
            "Requirement already satisfied: tokenizers<0.20,>=0.19 in /usr/local/lib/python3.10/dist-packages (from transformers) (0.19.1)\n",
            "Requirement already satisfied: safetensors>=0.4.1 in /usr/local/lib/python3.10/dist-packages (from transformers) (0.4.3)\n",
            "Requirement already satisfied: tqdm>=4.27 in /usr/local/lib/python3.10/dist-packages (from transformers) (4.66.4)\n",
            "Requirement already satisfied: fsspec>=2023.5.0 in /usr/local/lib/python3.10/dist-packages (from huggingface-hub<1.0,>=0.19.3->transformers) (2023.6.0)\n",
            "Requirement already satisfied: typing-extensions>=3.7.4.3 in /usr/local/lib/python3.10/dist-packages (from huggingface-hub<1.0,>=0.19.3->transformers) (4.11.0)\n",
            "Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.10/dist-packages (from requests->transformers) (3.3.2)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.10/dist-packages (from requests->transformers) (3.7)\n",
            "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.10/dist-packages (from requests->transformers) (2.0.7)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.10/dist-packages (from requests->transformers) (2024.2.2)\n"
          ]
        }
      ],
      "source": [
        "#installing required APIs\n",
        "!pip install transformers youtube-transcript-api sentencepiece"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "pOGRfe_j1Hes"
      },
      "outputs": [],
      "source": [
        "#Importing Requirements\n",
        "import pandas as pd\n",
        "from youtube_transcript_api import YouTubeTranscriptApi as YTapi\n",
        "from transformers import AutoTokenizer, AutoModelForSeq2SeqLM"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "GaKQch8i1Het"
      },
      "source": [
        "## Exploring API <a class=\"anchor\" id=\"ExploringAPI\"></a>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "o7GgKE_p1Het"
      },
      "outputs": [],
      "source": [
        "youtube_link = \"https://www.youtube.com/watch?v=FM7Z-Xq8Drc\""
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "CfJ7EC-m1Heu"
      },
      "outputs": [],
      "source": [
        "def videoID(link):\n",
        "    video_id = link.split(\"=\")[1]\n",
        "    return video_id"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 35
        },
        "id": "PzxhnJAK1Heu",
        "outputId": "e002f8d0-3f4b-4c7a-9941-2cbee003bb3a"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "'FM7Z-Xq8Drc'"
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            }
          },
          "metadata": {},
          "execution_count": 5
        }
      ],
      "source": [
        "id = videoID(youtube_link)\n",
        "id"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "B0y1s8GU1Hev"
      },
      "outputs": [],
      "source": [
        "def GetTranscript(video_id):\n",
        "    try:\n",
        "        transcript = YTapi.get_transcript(video_id)\n",
        "        FinalTranscript = ' '.join([i['text'] for i in transcript])\n",
        "    except Exception as e:\n",
        "        print(e)\n",
        "\n",
        "    return FinalTranscript"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "MTSqN2v81Hev"
      },
      "outputs": [],
      "source": [
        "transcript_en = GetTranscript(id)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "9ZXYW-rz1Hev"
      },
      "source": [
        "Using Auto-translate feature from YouTube which allows automatically translation of subtitles:\n",
        "\n",
        "1. Retrieve the available transcripts\n",
        "2. Iterate over all available transcripts\n",
        "3. Translating the transcript"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "GcX3YInF1Hew",
        "outputId": "deee8e9b-8905-4802-aed6-dcf74f5e3231"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Arabic True\n",
            "Chinese True\n",
            "English True\n",
            "French True\n",
            "German True\n",
            "Hindi True\n",
            "Italian True\n",
            "Japanese True\n",
            "Korean True\n",
            "Polish True\n",
            "Portuguese True\n",
            "Russian True\n",
            "Spanish True\n",
            "Turkish True\n",
            "English (auto-generated) True\n"
          ]
        }
      ],
      "source": [
        "transcript_list  = YTapi.list_transcripts(id)\n",
        "\n",
        "for transcript in transcript_list:\n",
        "    ln = transcript.language\n",
        "    check = transcript.is_translatable\n",
        "    print(ln, check)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ZYV_iqUp1Hew"
      },
      "source": [
        "Transcript for this youtube video is available in multiple langauge, and I'm choosig Hindi language and to check all the available  langauge, run follwing code:"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "X9A1_4UN1Hex",
        "outputId": "78ceb39b-196a-46a7-f777-13e75069a020"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[{'language': 'Afrikaans', 'language_code': 'af'}, {'language': 'Akan', 'language_code': 'ak'}, {'language': 'Albanian', 'language_code': 'sq'}, {'language': 'Amharic', 'language_code': 'am'}, {'language': 'Arabic', 'language_code': 'ar'}, {'language': 'Armenian', 'language_code': 'hy'}, {'language': 'Assamese', 'language_code': 'as'}, {'language': 'Aymara', 'language_code': 'ay'}, {'language': 'Azerbaijani', 'language_code': 'az'}, {'language': 'Bangla', 'language_code': 'bn'}, {'language': 'Basque', 'language_code': 'eu'}, {'language': 'Belarusian', 'language_code': 'be'}, {'language': 'Bhojpuri', 'language_code': 'bho'}, {'language': 'Bosnian', 'language_code': 'bs'}, {'language': 'Bulgarian', 'language_code': 'bg'}, {'language': 'Burmese', 'language_code': 'my'}, {'language': 'Catalan', 'language_code': 'ca'}, {'language': 'Cebuano', 'language_code': 'ceb'}, {'language': 'Chinese (Simplified)', 'language_code': 'zh-Hans'}, {'language': 'Chinese (Traditional)', 'language_code': 'zh-Hant'}, {'language': 'Corsican', 'language_code': 'co'}, {'language': 'Croatian', 'language_code': 'hr'}, {'language': 'Czech', 'language_code': 'cs'}, {'language': 'Danish', 'language_code': 'da'}, {'language': 'Divehi', 'language_code': 'dv'}, {'language': 'Dutch', 'language_code': 'nl'}, {'language': 'English', 'language_code': 'en'}, {'language': 'Esperanto', 'language_code': 'eo'}, {'language': 'Estonian', 'language_code': 'et'}, {'language': 'Ewe', 'language_code': 'ee'}, {'language': 'Filipino', 'language_code': 'fil'}, {'language': 'Finnish', 'language_code': 'fi'}, {'language': 'French', 'language_code': 'fr'}, {'language': 'Galician', 'language_code': 'gl'}, {'language': 'Ganda', 'language_code': 'lg'}, {'language': 'Georgian', 'language_code': 'ka'}, {'language': 'German', 'language_code': 'de'}, {'language': 'Greek', 'language_code': 'el'}, {'language': 'Guarani', 'language_code': 'gn'}, {'language': 'Gujarati', 'language_code': 'gu'}, {'language': 'Haitian Creole', 'language_code': 'ht'}, {'language': 'Hausa', 'language_code': 'ha'}, {'language': 'Hawaiian', 'language_code': 'haw'}, {'language': 'Hebrew', 'language_code': 'iw'}, {'language': 'Hindi', 'language_code': 'hi'}, {'language': 'Hmong', 'language_code': 'hmn'}, {'language': 'Hungarian', 'language_code': 'hu'}, {'language': 'Icelandic', 'language_code': 'is'}, {'language': 'Igbo', 'language_code': 'ig'}, {'language': 'Indonesian', 'language_code': 'id'}, {'language': 'Irish', 'language_code': 'ga'}, {'language': 'Italian', 'language_code': 'it'}, {'language': 'Japanese', 'language_code': 'ja'}, {'language': 'Javanese', 'language_code': 'jv'}, {'language': 'Kannada', 'language_code': 'kn'}, {'language': 'Kazakh', 'language_code': 'kk'}, {'language': 'Khmer', 'language_code': 'km'}, {'language': 'Kinyarwanda', 'language_code': 'rw'}, {'language': 'Korean', 'language_code': 'ko'}, {'language': 'Krio', 'language_code': 'kri'}, {'language': 'Kurdish', 'language_code': 'ku'}, {'language': 'Kyrgyz', 'language_code': 'ky'}, {'language': 'Lao', 'language_code': 'lo'}, {'language': 'Latin', 'language_code': 'la'}, {'language': 'Latvian', 'language_code': 'lv'}, {'language': 'Lingala', 'language_code': 'ln'}, {'language': 'Lithuanian', 'language_code': 'lt'}, {'language': 'Luxembourgish', 'language_code': 'lb'}, {'language': 'Macedonian', 'language_code': 'mk'}, {'language': 'Malagasy', 'language_code': 'mg'}, {'language': 'Malay', 'language_code': 'ms'}, {'language': 'Malayalam', 'language_code': 'ml'}, {'language': 'Maltese', 'language_code': 'mt'}, {'language': 'Māori', 'language_code': 'mi'}, {'language': 'Marathi', 'language_code': 'mr'}, {'language': 'Mongolian', 'language_code': 'mn'}, {'language': 'Nepali', 'language_code': 'ne'}, {'language': 'Northern Sotho', 'language_code': 'nso'}, {'language': 'Norwegian', 'language_code': 'no'}, {'language': 'Nyanja', 'language_code': 'ny'}, {'language': 'Odia', 'language_code': 'or'}, {'language': 'Oromo', 'language_code': 'om'}, {'language': 'Pashto', 'language_code': 'ps'}, {'language': 'Persian', 'language_code': 'fa'}, {'language': 'Polish', 'language_code': 'pl'}, {'language': 'Portuguese', 'language_code': 'pt'}, {'language': 'Punjabi', 'language_code': 'pa'}, {'language': 'Quechua', 'language_code': 'qu'}, {'language': 'Romanian', 'language_code': 'ro'}, {'language': 'Russian', 'language_code': 'ru'}, {'language': 'Samoan', 'language_code': 'sm'}, {'language': 'Sanskrit', 'language_code': 'sa'}, {'language': 'Scottish Gaelic', 'language_code': 'gd'}, {'language': 'Serbian', 'language_code': 'sr'}, {'language': 'Shona', 'language_code': 'sn'}, {'language': 'Sindhi', 'language_code': 'sd'}, {'language': 'Sinhala', 'language_code': 'si'}, {'language': 'Slovak', 'language_code': 'sk'}, {'language': 'Slovenian', 'language_code': 'sl'}, {'language': 'Somali', 'language_code': 'so'}, {'language': 'Southern Sotho', 'language_code': 'st'}, {'language': 'Spanish', 'language_code': 'es'}, {'language': 'Sundanese', 'language_code': 'su'}, {'language': 'Swahili', 'language_code': 'sw'}, {'language': 'Swedish', 'language_code': 'sv'}, {'language': 'Tajik', 'language_code': 'tg'}, {'language': 'Tamil', 'language_code': 'ta'}, {'language': 'Tatar', 'language_code': 'tt'}, {'language': 'Telugu', 'language_code': 'te'}, {'language': 'Thai', 'language_code': 'th'}, {'language': 'Tigrinya', 'language_code': 'ti'}, {'language': 'Tsonga', 'language_code': 'ts'}, {'language': 'Turkish', 'language_code': 'tr'}, {'language': 'Turkmen', 'language_code': 'tk'}, {'language': 'Ukrainian', 'language_code': 'uk'}, {'language': 'Urdu', 'language_code': 'ur'}, {'language': 'Uyghur', 'language_code': 'ug'}, {'language': 'Uzbek', 'language_code': 'uz'}, {'language': 'Vietnamese', 'language_code': 'vi'}, {'language': 'Welsh', 'language_code': 'cy'}, {'language': 'Western Frisian', 'language_code': 'fy'}, {'language': 'Xhosa', 'language_code': 'xh'}, {'language': 'Yiddish', 'language_code': 'yi'}, {'language': 'Yoruba', 'language_code': 'yo'}, {'language': 'Zulu', 'language_code': 'zu'}]\n"
          ]
        }
      ],
      "source": [
        "for transcript in transcript_list:\n",
        "    available_ln = transcript.translation_languages\n",
        "print(available_ln)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "v1zCLbDs1Hex"
      },
      "outputs": [],
      "source": [
        " transcript_hi = ' '.join([i['text'] for i in transcript.translate('hi').fetch()])"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "lcAv0c0z1Hey"
      },
      "source": [
        "##Printing only first 300 character of both Hindi and English transcript."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 70
        },
        "id": "5oaBtQ041Hey",
        "outputId": "eb811f2b-7235-47cb-8794-59bdcba9db1b"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "\"- Behind me are 100 people. And they range from the age one all the way through age 100. And I've trapped each of them\\nin their very own glass cube. The last one to leave\\ntheir cube is going to win half a million dollars. The challenge has officially begun. Let's see which age is the best. - So, I'm\""
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            }
          },
          "metadata": {},
          "execution_count": 11
        }
      ],
      "source": [
        "#Transcripting the youtube video in english\n",
        "transcript_en[:300]"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 52
        },
        "id": "O28JrR3a1Hey",
        "outputId": "b89f1da7-75df-4bba-dced-69bcb1eb8203"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "'मेरे पीछे 100 लोग हैं और उनमें एक वर्ष से लेकर 100 वर्ष की आयु तक के लोग हैं और मैंने उनमें से प्रत्येक को अपने स्वयं के ग्लास क्यूब में फंसा लिया है, जो अंतिम व्यक्ति अपना क्यूब छोड़ेगा वह आधा मिलियन डॉलर जीतने जा रहा है, यह चुनौती है आधिकारिक तौर पर शुरू हो गया है, आइए देखें कि कौन सी उम्र सबसे अच'"
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            }
          },
          "metadata": {},
          "execution_count": 12
        }
      ],
      "source": [
        "#transcripting youtube video in hindi\n",
        "transcript_hi[:300]"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ixY33kDL1Hez"
      },
      "source": [
        "## Applying Models <a class=\"anchor\" id=\"Models\"></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "h4IJFe7W1Hez"
      },
      "source": [
        "Applying `Pegasus` and `Bart` on English transcript and using `mT5` on the Hindi transcript."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "L6SDj7GG1He0"
      },
      "outputs": [],
      "source": [
        "checkpoint1 = \"google/pegasus-large\"\n",
        "checkpoint2 = \"csebuetnlp/mT5_multilingual_XLSum\"\n",
        "checkpoint3 = \"sshleifer/distilbart-cnn-12-6\"\n",
        "checkpoint4 = \"ai4bharat/IndicBART\""
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "hPhPbUs71He0"
      },
      "source": [
        "####Downloading Models"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "OsnogVZr1He0",
        "outputId": "081ec612-cd87-4894-f664-389a40835632"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/huggingface_hub/utils/_token.py:88: UserWarning: \n",
            "The secret `HF_TOKEN` does not exist in your Colab secrets.\n",
            "To authenticate with the Hugging Face Hub, create a token in your settings tab (https://huggingface.co/settings/tokens), set it as secret in your Google Colab and restart your session.\n",
            "You will be able to reuse this secret in all of your notebooks.\n",
            "Please note that authentication is recommended but still optional to access public models or datasets.\n",
            "  warnings.warn(\n",
            "Some weights of PegasusForConditionalGeneration were not initialized from the model checkpoint at google/pegasus-large and are newly initialized: ['model.decoder.embed_positions.weight', 'model.encoder.embed_positions.weight']\n",
            "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
          ]
        }
      ],
      "source": [
        "tokenizer1 = AutoTokenizer.from_pretrained(checkpoint1)\n",
        "model1 = AutoModelForSeq2SeqLM.from_pretrained(checkpoint1)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "G-309V221He0",
        "outputId": "b58227b0-7a3f-499b-97f1-e6760ef7216c"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "You are using the default legacy behaviour of the <class 'transformers.models.t5.tokenization_t5.T5Tokenizer'>. This is expected, and simply means that the `legacy` (previous) behavior will be used so nothing changes for you. If you want to use the new behaviour, set `legacy=False`. This should only be set if you understand what it means, and thoroughly read the reason why this was added as explained in https://github.com/huggingface/transformers/pull/24565\n",
            "/usr/local/lib/python3.10/dist-packages/transformers/convert_slow_tokenizer.py:560: UserWarning: The sentencepiece tokenizer that you are converting to a fast tokenizer uses the byte fallback option which is not implemented in the fast tokenizers. In practice this means that the fast version of the tokenizer can produce unknown tokens whereas the sentencepiece version would have converted these unknown tokens into a sequence of byte tokens matching the original piece of text.\n",
            "  warnings.warn(\n"
          ]
        }
      ],
      "source": [
        "tokenizer2 = AutoTokenizer.from_pretrained(checkpoint2)\n",
        "model2 = AutoModelForSeq2SeqLM.from_pretrained(checkpoint2)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "vXavQ8_A1He1"
      },
      "outputs": [],
      "source": [
        "tokenizer3 = AutoTokenizer.from_pretrained(checkpoint3)\n",
        "model3 = AutoModelForSeq2SeqLM.from_pretrained(checkpoint3)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "GXtTJXn11He1",
        "outputId": "7f87d4d6-5b90-4cf8-f707-0420008e0289"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Special tokens have been added in the vocabulary, make sure the associated word embeddings are fine-tuned or trained.\n",
            "Special tokens have been added in the vocabulary, make sure the associated word embeddings are fine-tuned or trained.\n"
          ]
        }
      ],
      "source": [
        "tokenizer4 = AutoTokenizer.from_pretrained(checkpoint4)\n",
        "model4 = AutoModelForSeq2SeqLM.from_pretrained(checkpoint4)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "45lpTFmd1He1"
      },
      "outputs": [],
      "source": [
        "def summarize(toenizer, model, text):\n",
        "\n",
        "    \"\"\"\n",
        "    Function to summarize the text(transcript)\n",
        "    \"\"\"\n",
        "    inputs = toenizer(text,\n",
        "                    max_length=1024,\n",
        "                    truncation=True,\n",
        "                    return_tensors=\"pt\")\n",
        "\n",
        "    summary_ids = model.generate(inputs[\"input_ids\"])\n",
        "    summary = toenizer.batch_decode(summary_ids,\n",
        "                                  skip_special_tokens=True,\n",
        "                                  clean_up_tokenization_spaces=False)\n",
        "    return summary"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "rAv8mgkp1He2"
      },
      "source": [
        "**English Summary**"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "fxiE3DlY1He2"
      },
      "outputs": [],
      "source": [
        "pegasus = summarize(tokenizer1, model1, transcript_en)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "2SMLjkBY1He2",
        "outputId": "bb6eb3cf-400a-4323-fa7a-632d8d3ad031"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "\"And they range from the age one all the way through age 100. The last one to leave their cube is going to win half a million dollars. I've got the best view and the best motivation. Keep in mind, I have over 300 cameras set up literally everywhere, so we'll be monitoring their every move. Keep in mind, I have over 300 cameras set up literally everywhere, so we'll be monitoring their every move. - My strategy is to make a lot of noise, so people like you don't get any sleep and they really wanna get out. We're a couple hours into the challenge and 10 people have already gotten out. So, we decide to leave them alone for the rest of the day, which caused even more people to get out.\""
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            }
          },
          "metadata": {},
          "execution_count": 20
        }
      ],
      "source": [
        "pegasus[0]"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "smNMbo6H1He3"
      },
      "outputs": [],
      "source": [
        "bart = summarize(tokenizer3, model3, transcript_en)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 70
        },
        "id": "iGNiBmj31He3",
        "outputId": "6773b574-ef39-41c0-f4d5-e40907e1d065"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "' 100 people have been trapped in a glass cube for 24 hours in a bid to win half a million dollars . The last one to leave their glass cube is going to win $500,000 . Some of the kids had a crazy strategy to make a lot of noise to get out of the cube . Some draw on walls with deodorant, while others build pillow forts .'"
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            }
          },
          "metadata": {},
          "execution_count": 22
        }
      ],
      "source": [
        "bart[0]"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "9t23kaFm1He3"
      },
      "source": [
        "**Hindi Summary**"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "M7Gv5BLi1He4"
      },
      "outputs": [],
      "source": [
        "mt5 = summarize(tokenizer2, model2, transcript_hi)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "eANPa5D71He5",
        "outputId": "3bb91d7b-1fd8-4095-da0d-a50043ca659b"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "'मैं एक साल से भी अधिक समय तक अकेला रहना चाहता हूं और यह मेरे लिए एक चुनौती है.'"
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            }
          },
          "metadata": {},
          "execution_count": 24
        }
      ],
      "source": [
        "mt5[0]"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "4ZbQYnDG1He5",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "438fe121-eb2c-418b-b4ec-d3bbf5a6e133"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/transformers/generation/utils.py:1141: UserWarning: Using the model-agnostic default `max_length` (=20) to control the generation length. We recommend setting `max_new_tokens` to control the maximum length of the generation.\n",
            "  warnings.warn(\n"
          ]
        }
      ],
      "source": [
        "HiBart = summarize(tokenizer4, model4, transcript_hi)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 35
        },
        "id": "50Z3aQgr1He6",
        "outputId": "63be00a1-4759-4dc2-b293-1ec509b8896f"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "'मुंह मेरे पीछे 100 लोग हैं और उनमें एक वर्ष से लेकर 100 वर्ष की आयु तक के'"
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            }
          },
          "metadata": {},
          "execution_count": 26
        }
      ],
      "source": [
        "HiBart[0]"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "cwMNn03V1He8"
      },
      "source": [
        "-----"
      ]
    }
  ],
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.6.4"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}